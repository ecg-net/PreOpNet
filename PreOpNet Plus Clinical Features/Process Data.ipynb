{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import xmltodict\n",
    "import base64\n",
    "import struct\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "args = {\n",
    "    'in_XML' : '/workspace/data/NAS/Muse2013-19ECGs_XML', # where the XML files are located, put none if these are already calculated\n",
    "    'in_csv': '/workspace/data/NAS/Cedars EKG Analysis/Muse2008-19 XML Metadata.csv',# Where the csv is located for your input dataset\n",
    "    'in_dataset': '/workspace/data/drives/Internal_SSD/sdc/EKG Test/',# Where the converted XMLs will be moved, or, where the numpy arrays are currently stored\n",
    "    'out_dataset': '/workspace/data/drives/Internal_SSD/sdc/Comparison/', # Where the normalized EKGs are stored\n",
    "    'sample':100000, # sample size to estimate mean and standard deviation\n",
    "    'mean':np.array([-0.753910531911661,-0.5609376530271284,0.19297287888453685,0.6574240924693946,-0.09648643944226842,0.09648643944226842,-0.9398182103547104,-0.8866948773251518,-0.9585726095365399,-0.9142084935751398,-0.9573448180888456,-0.9300810636208064]),\n",
    "    'std':np.array([32.082092358503644,34.97862852596865,38.153409045189754,27.612712586528637,19.076704522594877,19.076704522594877,42.77931881050877,63.872623440588406,61.15731462396783,54.12879139607189,48.435274440820855,43.34056377213695])\n",
    "    \n",
    "}# replace mean and std with none to calculate your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def file_path(path):\n",
    "    return os.listdir(path)\n",
    "    \n",
    "#need to update this function to check the output directory for the output file and then only on newly added EKGs\n",
    "#add timestamp to start file string \n",
    "#this is annoying because the XML file name is a random timestamp and the output file is the UniqueECGID\n",
    "\n",
    "\n",
    "#if not os.path.exists('/D:/Muse2019ECGs_npy/'):\n",
    "#    os.mkdir('/D:/Muse2019ECGs_npy/')\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Input and outputs for XML EKG parsing')\n",
    "# parser.add_argument('input', type=str)\n",
    "# parser.set_defaults(output=os.getcwd() + '/EchoNet_ECG_waveforms/') #ensure this directory already exists\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "def decode_ekg_muse(raw_wave):\n",
    "    \"\"\"\n",
    "    Ingest the base64 encoded waveforms and transform to numeric\n",
    "    \"\"\"\n",
    "    # covert the waveform from base64 to byte array\n",
    "    arr = base64.b64decode(bytes(raw_wave, 'utf-8'))\n",
    "\n",
    "    # unpack every 2 bytes, little endian (16 bit encoding)\n",
    "    unpack_symbols = ''.join([char*int(len(arr)/2) for char in 'h'])\n",
    "    byte_array = struct.unpack(unpack_symbols,  arr)\n",
    "    return byte_array\n",
    "\n",
    "\n",
    "def decode_ekg_muse_to_array(raw_wave, downsample = 1):\n",
    "    \"\"\"\n",
    "    Ingest the base64 encoded waveforms and transform to numeric\n",
    "    downsample: 0.5 takes every other value in the array. Muse samples at 500/s and the sample model requires 250/s. So take every other.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dwnsmpl = int(1//downsample)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"You must downsample by more than 0\")\n",
    "    # covert the waveform from base64 to byte array\n",
    "    arr = base64.b64decode(bytes(raw_wave, 'utf-8'))\n",
    "\n",
    "    # unpack every 2 bytes, little endian (16 bit encoding)\n",
    "    unpack_symbols = ''.join([char*int(len(arr)/2) for char in 'h'])\n",
    "    byte_array = struct.unpack(unpack_symbols,  arr)\n",
    "    return np.array(byte_array)[::dwnsmpl]\n",
    "\n",
    "\n",
    "\n",
    "def xml_to_np_array_file(path_to_xml, path_to_output = os.getcwd(),df=None):\n",
    "    with open(path_to_xml, 'rb') as fd:\n",
    "        dic = xmltodict.parse(fd.read().decode('utf8'))\n",
    "    \n",
    "    \"\"\"\n",
    "    Upload the ECG as numpy array with shape=[5000,12] ([time, leads, 1]).\n",
    "    The voltage unit should be in 1 mv/unit and the sampling rate should be 250/second (total 10 second).\n",
    "    The leads should be ordered as follow I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pt_id = dic['RestingECG']['PatientDemographics']['PatientID']\n",
    "    except:\n",
    "        pt_id = \"none\"\n",
    "    try:\n",
    "        PharmaUniqueECGID = dic['RestingECG']['PharmaData']['PharmaUniqueECGID']\n",
    "    except:\n",
    "        PharmaUniqueECGID = \"none\"\n",
    "    try:\n",
    "        AcquisitionDateTime = dic['RestingECG']['TestDemographics']['AcquisitionDate'] + \"_\" + dic['RestingECG']['TestDemographics']['AcquisitionTime'].replace(\":\",\"-\")\n",
    "    except:\n",
    "        AcquisitionDateTime = \"none\"    \n",
    "\n",
    "    # try:\n",
    "    #     requisition_number = dic['RestingECG']['Order']['RequisitionNumber']\n",
    "    # except:\n",
    "    #     print(\"no requisition_number\")\n",
    "    #     requisition_number = \"none\"\n",
    "\n",
    "    #need to instantiate leads in the proper order for the model\n",
    "    lead_order = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "\n",
    "    \"\"\"\n",
    "    Each EKG will have this data structure:\n",
    "    lead_data = {\n",
    "        'I': np.array\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    lead_data =  dict.fromkeys(lead_order)\n",
    "    #lead_data = {leadid: None for k in lead_order}\n",
    "\n",
    "#     for all_lead_data in dic['RestingECG']['Waveform']:\n",
    "#         for single_lead_data in lead['LeadData']:\n",
    "#             leadname =  single_lead_data['LeadID']\n",
    "#             if leadname in (lead_order):\n",
    "\n",
    "    for lead in dic['RestingECG']['Waveform']:\n",
    "        for leadid in range(len(lead['LeadData'])):\n",
    "                sample_length = len(decode_ekg_muse_to_array(lead['LeadData'][leadid]['WaveFormData']))\n",
    "                #sample_length is equivalent to dic['RestingECG']['Waveform']['LeadData']['LeadSampleCountTotal']\n",
    "                if sample_length == 5000 or sample_length == 5500:\n",
    "                    lead_data[lead['LeadData'][leadid]['LeadID']] = decode_ekg_muse_to_array(lead['LeadData'][leadid]['WaveFormData'], downsample = 1)\n",
    "                elif sample_length == 2500:\n",
    "                    raise ValueError(\"Sample frequency too low, try with frequency = 500/s\")\n",
    "                else:\n",
    "                    continue\n",
    "            #ensures all leads have 2500 samples and also passes over the 3 second waveform\n",
    "    lead_data['III'] = (np.array(lead_data[\"II\"]) - np.array(lead_data[\"I\"]))\n",
    "    lead_data['aVR'] = -(np.array(lead_data[\"I\"]) + np.array(lead_data[\"II\"]))/2\n",
    "    lead_data['aVF'] = (np.array(lead_data[\"II\"]) - np.array(lead_data[\"I\"]))/2\n",
    "    lead_data['aVL'] = (np.array(lead_data[\"I\"]) - np.array(lead_data[\"II\"]))/2\n",
    "    \n",
    "    lead_data = {k: lead_data[k] for k in lead_order}\n",
    "    # drops V3R, V4R, and V7 if it was a 15-lead ECG\n",
    "\n",
    "    # now construct and reshape the array\n",
    "    # converting the dictionary to an np.array\n",
    "    temp = []\n",
    "    for key,value in lead_data.items():\n",
    "        temp.append(value)\n",
    "\n",
    "    #transpose to be [time, leads, ]\n",
    "    ekg_array = np.array(temp).T\n",
    "\n",
    "    #expand dims to [time, leads, 1]\n",
    "    ekg_array = np.expand_dims(ekg_array,  axis=-1)\n",
    "\n",
    "    # Here is a check to make sure all the model inputs are the right shape\n",
    "#     assert ekg_array.shape == (2500, 12, 1), \"ekg_array is shape {} not (2500, 12, 1)\".format(ekg_array.shape )\n",
    "\n",
    "    # filename = '/ekg_waveform_{}_{}.npy'.format(pt_id, requisition_number)\n",
    "    filename = '{}_{}_{}.npy'.format(pt_id, AcquisitionDateTime,PharmaUniqueECGID)\n",
    "    path_to_output = os.path.join(path_to_output,filename)\n",
    "    # print(path_to_output)\n",
    "    if len(ekg_array.shape)==3:\n",
    "        ekg_array = ekg_array[:,:,0]\n",
    "    # if len(ekg_array) == 5500:\n",
    "    #     ekg_array = ekg_array[:-500,:]\n",
    "    with open(path_to_output, 'wb') as f:\n",
    "        np.save(f, ekg_array)\n",
    "    if not type(df) == type(pd.DataFrame()):\n",
    "        col = list(dic['RestingECG']['PatientDemographics'].keys())\n",
    "        col.append(\"Filename\")\n",
    "        col.append('LocationName')\n",
    "        col.append('SiteName')\n",
    "        for key in dic['RestingECG']['RestingECGMeasurements'].keys():\n",
    "            col.append(key)\n",
    "        col.append('DiagnosisStatement')\n",
    "        col.append('TestReason')\n",
    "        col.append('AdmitDiagnosis')\n",
    "        col.append('xmlFilename')\n",
    "        df = pd.DataFrame(columns=col)\n",
    "    pid = dic['RestingECG']['PatientDemographics']\n",
    "    pid['Filename']=filename\n",
    "    pid['LocationName']=dic['RestingECG']['TestDemographics']['LocationName']\n",
    "    pid['SiteName']= dic['RestingECG']['TestDemographics']['SiteName']\n",
    "    for key in dic['RestingECG']['RestingECGMeasurements'].keys():\n",
    "        pid[key]=dic['RestingECG']['RestingECGMeasurements'][key]\n",
    "    \n",
    "    try:\n",
    "        pid['AdmitDiagnosis'] = dic['RestingECG']['Order']['AdmitDiagnosis']\n",
    "    except:\n",
    "        pid['AdmitDiagnosis'] = ''\n",
    "    try:\n",
    "        pid['TestReason'] = dic['RestingECG']['TestDemographics']['TestReason']\n",
    "    except:\n",
    "        pid['TestReason'] = ''\n",
    "    \n",
    "    try:\n",
    "        s = ''\n",
    "        for sen in dic['RestingECG']['Diagnosis']['DiagnosisStatement']:\n",
    "            s+=sen['StmtText']\n",
    "        pid['DiagnosisStatement'] = s\n",
    "    except:\n",
    "        pid['DiagnosisStatement'] = ''\n",
    "    pid['xmlFilename'] = path_to_xml.split('/')[-1]\n",
    "    df=df.append(pid,ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def ekg_batch_run(ekg_list,args):\n",
    "    i = 0\n",
    "    x = 0\n",
    "    df = 1\n",
    "    for file in tqdm(ekg_list):\n",
    "        try:\n",
    "            df = xml_to_np_array_file(os.path.join(args['in_XML'],file), args['in_dataset'],df=df)\n",
    "            i+=1\n",
    "        except Exception as e:\n",
    "\n",
    "            print(\"file failed: \", file)\n",
    "            print(file, e)\n",
    "            x+=1\n",
    "        if i % 10000 == 9999:\n",
    "            print(f\"Succesfully converted {i} EKGs, failed converting {x} EKGs\")\n",
    "            df.to_csv(os.path.join(args['in_dataset'],'Personal_Data.csv'),index=False)\n",
    "    df.to_csv(os.path.join(args['in_dataset'],'Personal_Data.csv'),index=False)\n",
    "    print(f\"Succesfully converted {i} EKGs, failed converting {x} EKGs\")\n",
    "\n",
    "if not args['in_XML'] is None:\n",
    "    ekg_file_list = []\n",
    "    ekg_file_list = file_path(args['in_XML'])  #if you want input to be a directory\n",
    "    print(\"Number of EKGs found: \", len(ekg_file_list))\n",
    "\n",
    "    ekg_batch_run(ekg_file_list,args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(n1,s1,n2,s2,y1,y2,y):\n",
    "    top = n1*(s1**2)+n1*(s1**2) + n1*((y1-y)**2)+n2*((y2-y)**2)\n",
    "    bot = n1+n2\n",
    "    return np.sqrt(top/bot)\n",
    "def calc_mean_std(arr,mean,stds,count):\n",
    "    count_t = count+1\n",
    "    arr_mean = np.mean(arr,axis=0)\n",
    "    arr_std = np.std(arr,axis=0)\n",
    "    new_mean = arr_mean*1/count_t + mean * (count_t-1)/count_t\n",
    "    return new_mean,std(5000,arr_std,5000*count,stds,arr_mean,mean,new_mean)\n",
    "\n",
    "\n",
    "fnames = pd.read_csv(args['in_csv']).Filename\n",
    "out = args['out_dataset']\n",
    "input_dir = args['in_dataset']\n",
    "trainData = []\n",
    "\n",
    "cur_mean = None\n",
    "cur_std = None\n",
    "\n",
    "arr = np.zeros(12)\n",
    "count = 1\n",
    "if args['mean'] is None:\n",
    "    for npfile in tqdm(np.random.choice(fnames,args['sample'])):\n",
    "        path = os.path.join(input_dir,npfile)\n",
    "        file = np.load(path)\n",
    "        trainData.append(file)\n",
    "\n",
    "    trainData = np.array([trainData])\n",
    "    m = []\n",
    "\n",
    "    s = []\n",
    "    for i in tqdm(range(0,12)):\n",
    "        m.append(np.mean(trainData[:,:,:,i]))\n",
    "        s.append(np.std(trainData[:,:,:,i],axis=None))\n",
    "else:\n",
    "    print(\"Existing mean and std\")\n",
    "    m = args['mean']\n",
    "    s = args['std']\n",
    "del trainData\n",
    "for i in tqdm(fnames):\n",
    "    if not os.path.exists(os.path.join(out,i)):\n",
    "        file = np.load(os.path.join(input_dir,i))\n",
    "        for k in range(0,12):\n",
    "            file[:,k] = (file[:,k] - m[k])/s[k]\n",
    "\n",
    "        np.save(os.path.join(out,i),file)\n",
    "print(\"Finished\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
