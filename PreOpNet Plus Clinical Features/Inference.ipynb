{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import models\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from pthflops import count_ops\n",
    "\n",
    "import pandas as pd\n",
    "from ECG import ECG_loader\n",
    "def get_model(depth = [1,2,2,3,3,3,3],channels = [32,16,24,40,80,112,192,320,1280],dilation = 1,stride = 2,expansion = 6,additional_inputs=0):\n",
    "    model = models.EffNet(depth = depth,channels = channels,dilation = dilation,stride = stride,expansion = expansion,num_additional_features=additional_inputs)\n",
    "    print('parameters: ' +str(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def point(y_total,yhat_total,t):\n",
    "    specificity = []\n",
    "    sensitivity = []\n",
    "    for i in tqdm(t):\n",
    "        tn, fp, fn, tp = confusion_matrix(y_total, yhat_total>i).ravel()\n",
    "        specificity.append( tn / (tn+fp) )\n",
    "        sensitivity.append( tp / (tp+fn) )\n",
    "    return t[(np.array(specificity) + np.array(sensitivity) - 1).argmax()]\n",
    "def thresholded_output_transform(yhat,y):\n",
    "    y_pred, y = yhat,y\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    return y_pred, y\n",
    "def produce_df(test_loader, checkpoint,folder = 'Test Results', depth = [1,2,2,3,3,3,3],channels = [32,16,24,40,80,112,192,320,1280],dilation = 1,stride = 2,expansion = 6,additional_inputs = 0,ds = None):\n",
    "    \n",
    "    # load model and checkpoint\n",
    "    model = get_model(depth = depth,channels = channels,dilation = dilation,stride = stride,expansion = expansion, additional_inputs=additional_inputs)\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to('cpu')\n",
    "    yhat = torch.Tensor()\n",
    "    \n",
    "    # Calculate FLOPs\n",
    "    if not ds is None:\n",
    "        dl=torch.utils.data.DataLoader(ds, batch_size=1,num_workers=10,drop_last=False)\n",
    "        for x,y in dl:\n",
    "            count_ops(model,x)\n",
    "            break\n",
    "\n",
    "    # produce tensors\n",
    "    y_total = torch.Tensor()\n",
    "    yhat_total = torch.Tensor()\n",
    "    for x,y in tqdm(test_loader):\n",
    "        yhat = model(x)\n",
    "        yhat,y = thresholded_output_transform(yhat,y)\n",
    "        y_total = torch.cat((y_total,y),0)\n",
    "        yhat_total = torch.cat((yhat_total,yhat.detach().cpu()),0)\n",
    "    \n",
    "    # Save predictions\n",
    "    df = pd.DataFrame({'labels':y_total.flatten().tolist(),'Prediction':yhat_total.flatten().tolist()})\n",
    "    \n",
    "    # Produce ROC and CM\n",
    "    fpr,tpr, t = roc_curve(y_total,yhat_total)\n",
    "    thresh = point(y_total,yhat_total,t)\n",
    "    lw = 2\n",
    "    cm(y_total.flatten(),yhat_total.flatten(),folder=folder,threshold = thresh)\n",
    "    bootstrap(df)\n",
    "    return yhat_total, y_total, fpr, tpr, t\n",
    "def bootstrap(df):\n",
    "    y_total,yhat_total = df['labels'],df['Prediction']\n",
    "    fpr_boot = []\n",
    "    tpr_boot = []\n",
    "    aucs = []\n",
    "    \n",
    "    # bootstrap for confidence interval\n",
    "    for i in tqdm(range(0,10000)):\n",
    "        choices = np.random.choice(range(0,len(yhat_total)),int(len(yhat_total)/2))\n",
    "        fpr,tpr, _ = roc_curve(y_total[choices],yhat_total[choices])\n",
    "        fpr_boot.append(fpr)\n",
    "        tpr_boot.append(tpr)\n",
    "        aucs.append(auc(fpr,tpr))\n",
    "    low,high = np.nanmean(aucs)-np.nanstd(aucs)*1.96,np.nanmean(aucs)+np.nanstd(aucs)*1.96\n",
    "    lower_point = round(np.percentile(aucs,2.5),2)\n",
    "    higher_point = round(np.percentile(aucs,97.5),2)\n",
    "    mean_point = round(np.nanmean(aucs),2)\n",
    "    x = plt.hist(aucs,bins = 50,label = 'mean: '+str(mean_point))\n",
    "\n",
    "    plt.plot([np.percentile(aucs,2.5),np.percentile(aucs,2.5)],[0,max(x[0])],label = 'lower interval: '+str(lower_point))\n",
    "    plt.plot([np.percentile(aucs,97.5),np.percentile(aucs,97.5)],[0,max(x[0])],label = 'higher interval: '+str(higher_point))\n",
    "    plt.title(\"AUC Histogram\")\n",
    "    plt.xlabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    for i in range(0,1000):\n",
    "        plt.plot(fpr_boot[i],tpr_boot[i], color='lightblue',\n",
    "                 lw=lw)\n",
    "    fpr,tpr, _ = roc_curve(y_total,yhat_total)\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % auc(fpr,tpr))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "def cm(y_total,yhat_total,Project_name = None,folder=None,threshold = 0.5):\n",
    "    print(threshold)\n",
    "    cm = confusion_matrix(y_total,yhat_total>threshold)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_total,yhat_total>threshold).ravel()\n",
    "    specificity = ( tn / (tn+fp) )\n",
    "    sensitivity= ( tp / (tp+fn) )\n",
    "    print('Positive Predictive Value',round(tp/(tp+fp),2),'Negative Predictive Value', round(tn/(tn+fn),2), ' Specificty ', specificity, 'Sensitivity ', sensitivity)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['No Event','Adverse Event'])\n",
    "    disp.plot()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_root = '/workspace/John/IntroECG-main/IntroECG-main/data/Definitely Not A Mistake/'\n",
    "Val_csv = '/workspace/John/IntroECG-main/IntroECG-main/data/Test_rcri_outcome.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RCRINet on RCRI Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bs = 2000\n",
    "checkpoint = 'best_roc_model_Mortality_with_RCRI_Features.pt'\n",
    "additional_inputs = ['CrGreaterThan2','is_risk','insulin','cad','chf','stroke']\n",
    "\n",
    "test_ds = ECG_loader(root = Val_root, csv = Val_csv,sliding = False,downsample=1,additional_inputs=additional_inputs)\n",
    "val_dataloader=torch.utils.data.DataLoader(test_ds, batch_size=bs,num_workers=10,drop_last=False)\n",
    "x = produce_df(val_dataloader,checkpoint,folder = 'Spare',stride = 8, dilation = 2,additional_inputs=len(additional_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
